{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.datasets import ElectricityTiny\n",
    "from capymoa.anomaly import HalfSpaceTrees, TreeBasedUnsupervised, Autoencoder, StreamRHF\n",
    "from capymoa.evaluation import AnomalyDetectionEvaluator\n",
    "from capymoa.stream import stream_from_file\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.anomaly import StreamRHFParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset from paper to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved to: C:\\Users\\aleja\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\datasets\\forStefan\\data\\public\\abalone.csv\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "path_to_dataset = r\"C:\\Users\\aleja\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\datasets\\forStefan\\data\\public\"\n",
    "dataset_name = \"abalone\"\n",
    "\n",
    "# Construct input and output paths\n",
    "input_path = os.path.join(path_to_dataset, f\"{dataset_name}.gz\")\n",
    "output_path = os.path.join(path_to_dataset, f\"{dataset_name}.csv\")\n",
    "\n",
    "# Read the gzipped file and save it as a CSV\n",
    "with gzip.open(input_path, 'rt') as gz_file:\n",
    "    df = pd.read_csv(gz_file)\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"CSV saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create stream from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53   0.42   0.135  0.677  0.2565 0.1415 0.21  ]\n",
      "0\n",
      "2\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\stream\\_stream.py:38: UserWarning: target variable includes 2 (< 20) unique values, inferred as categorical, set target_type = 'numeric' if you intend numeric targets\n",
      "  warnings.warn(f'target variable includes {num_unique} (< 20) unique values, inferred as categorical, '\n"
     ]
    }
   ],
   "source": [
    "stream = stream_from_file(output_path, dataset_name=\"Abalone\")\n",
    "schema = stream.get_schema()\n",
    "instance = stream.next_instance()\n",
    "actual_value = instance.x\n",
    "label = instance.y_index\n",
    "print(actual_value)\n",
    "print(label)\n",
    "print(schema.get_num_classes())\n",
    "print(schema.get_num_attributes())\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our StreamRHF initialized\n",
      "20\n",
      "Processed 100 instances. Time spent: 109.63 seconds.\n",
      "Processed 200 instances. Time spent: 130.64 seconds.\n",
      "Processed 300 instances. Time spent: 129.74 seconds.\n",
      "Processed 400 instances. Time spent: 132.18 seconds.\n",
      "Processed 500 instances. Time spent: 121.18 seconds.\n",
      "Processed 600 instances. Time spent: 106.81 seconds.\n",
      "Processed 700 instances. Time spent: 104.51 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#print(proba)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#score â€“ The predicted scores. Should be in the range [0, 1].\u001b[39;00m\n\u001b[0;32m     16\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mupdate(instance\u001b[38;5;241m.\u001b[39my_index, proba)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m processed_instances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Print progress and elapsed time every 100 instances\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:263\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, instance)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, instance):\n\u001b[0;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m    Predict anomaly score for a single instance.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03m    This is effectively the same as scoring the instance.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    :param instance: An instance from the stream.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    :return: Anomaly score for the instance.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_instance(instance)\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:206\u001b[0m, in \u001b[0;36mRandomHistogramForest.update_forest\u001b[1;34m(self, instance)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforest\u001b[38;5;241m.\u001b[39mappend(tree)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforest):\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforest[i] \u001b[38;5;241m=\u001b[39m \u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed_arrays\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:100\u001b[0m, in \u001b[0;36minsert\u001b[1;34m(node, instance, max_height, seed_array)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattribute \u001b[38;5;241m!=\u001b[39m new_attribute:\n\u001b[0;32m     99\u001b[0m     subtree_data \u001b[38;5;241m=\u001b[39m collect_subtree_data(node, data_to_send\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRHT_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubtree_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance[node\u001b[38;5;241m.\u001b[39mattribute] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m    103\u001b[0m     node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m insert(node\u001b[38;5;241m.\u001b[39mleft, instance, max_height, seed_array)\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:86\u001b[0m, in \u001b[0;36mRHT_build\u001b[1;34m(data, height, max_height, seed_array, node_id)\u001b[0m\n\u001b[0;32m     83\u001b[0m right_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m>\u001b[39m split_value]\n\u001b[0;32m     85\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m RHT_build(left_data, height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_height, seed_array, node_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m node_id)\n\u001b[1;32m---> 86\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[43mRHT_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:86\u001b[0m, in \u001b[0;36mRHT_build\u001b[1;34m(data, height, max_height, seed_array, node_id)\u001b[0m\n\u001b[0;32m     83\u001b[0m right_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m>\u001b[39m split_value]\n\u001b[0;32m     85\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m RHT_build(left_data, height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_height, seed_array, node_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m node_id)\n\u001b[1;32m---> 86\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[43mRHT_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:85\u001b[0m, in \u001b[0;36mRHT_build\u001b[1;34m(data, height, max_height, seed_array, node_id)\u001b[0m\n\u001b[0;32m     82\u001b[0m left_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m split_value]\n\u001b[0;32m     83\u001b[0m right_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m>\u001b[39m split_value]\n\u001b[1;32m---> 85\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[43mRHT_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m RHT_build(right_data, height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_height, seed_array, node_id\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m node_id) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:86\u001b[0m, in \u001b[0;36mRHT_build\u001b[1;34m(data, height, max_height, seed_array, node_id)\u001b[0m\n\u001b[0;32m     83\u001b[0m right_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m>\u001b[39m split_value]\n\u001b[0;32m     85\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m RHT_build(left_data, height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_height, seed_array, node_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m node_id)\n\u001b[1;32m---> 86\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[43mRHT_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:85\u001b[0m, in \u001b[0;36mRHT_build\u001b[1;34m(data, height, max_height, seed_array, node_id)\u001b[0m\n\u001b[0;32m     82\u001b[0m left_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m split_value]\n\u001b[0;32m     83\u001b[0m right_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m>\u001b[39m split_value]\n\u001b[1;32m---> 85\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[43mRHT_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m RHT_build(right_data, height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_height, seed_array, node_id\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m node_id) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:85\u001b[0m, in \u001b[0;36mRHT_build\u001b[1;34m(data, height, max_height, seed_array, node_id)\u001b[0m\n\u001b[0;32m     82\u001b[0m left_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m split_value]\n\u001b[0;32m     83\u001b[0m right_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m>\u001b[39m split_value]\n\u001b[1;32m---> 85\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[43mRHT_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m RHT_build(right_data, height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_height, seed_array, node_id\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m node_id) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "    \u001b[1;31m[... skipping similar frames: RHT_build at line 85 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:85\u001b[0m, in \u001b[0;36mRHT_build\u001b[1;34m(data, height, max_height, seed_array, node_id)\u001b[0m\n\u001b[0;32m     82\u001b[0m left_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m split_value]\n\u001b[0;32m     83\u001b[0m right_data \u001b[38;5;241m=\u001b[39m data[data[:, attribute] \u001b[38;5;241m>\u001b[39m split_value]\n\u001b[1;32m---> 85\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[43mRHT_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m RHT_build(right_data, height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_height, seed_array, node_id\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m node_id) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\anomaly\\_stream_rhf.py:69\u001b[0m, in \u001b[0;36mRHT_build\u001b[1;34m(data, height, max_height, seed_array, node_id)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m idx\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kurt_values) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRHT_build\u001b[39m(data, height, max_height, seed_array, node_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     70\u001b[0m     node \u001b[38;5;241m=\u001b[39m Node(\u001b[38;5;28;01mNone\u001b[39;00m, height, max_height, seed_array[node_id], node_id)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m height \u001b[38;5;241m==\u001b[39m max_height \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "schema = stream.get_schema()\n",
    "learner = StreamRHF(schema, num_trees=100, max_height=10)\n",
    "evaluator = AnomalyDetectionEvaluator(schema)\n",
    "start_time = time.time()\n",
    "processed_instances = 0\n",
    "#while stream.has_more_instances():\n",
    "while processed_instances < 1000:\n",
    "    instance = stream.next_instance()\n",
    "    proba = learner.score_instance(instance)\n",
    "    if proba > 1:\n",
    "        print('probability bigger than 1 for instance ', instance.x)\n",
    "        print(proba)\n",
    "    #print(proba)\n",
    "    #score â€“ The predicted scores. Should be in the range [0, 1].\n",
    "    evaluator.update(instance.y_index, proba)\n",
    "    learner.train(instance)\n",
    "    processed_instances += 1\n",
    "    # Print progress and elapsed time every 100 instances\n",
    "    if processed_instances % 100 == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Processed {processed_instances} instances. Time spent: {elapsed_time:.2f} seconds.\")\n",
    "        start_time = time.time()  # Reset start time for the next 100 instances\n",
    "auc = evaluator.auc()\n",
    "print(f\"AUC: {auc:.2f} with StreamRHF\")\n",
    "stream.restart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.85 with Autoencoder\n"
     ]
    }
   ],
   "source": [
    "schema = stream.get_schema()\n",
    "learner = Autoencoder(schema)\n",
    "evaluator = AnomalyDetectionEvaluator(schema)\n",
    "while stream.has_more_instances():\n",
    "    instance = stream.next_instance()\n",
    "    #print('x ' + str(instance.x))\n",
    "    #print(\"type: \", type(instance.x))\n",
    "    #print('label ' + str(instance.y_index))\n",
    "    #print(\"type: \", type(instance.y_index))\n",
    "    proba = learner.score_instance(instance)\n",
    "    #print(proba)\n",
    "    #score â€“ The predicted scores. Should be in the range [0, 1].\n",
    "    evaluator.update(instance.y_index, proba)\n",
    "    learner.train(instance)\n",
    "auc = evaluator.auc()\n",
    "print(f\"AUC: {auc:.2f} with Autoencoder\")\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.NullPointerException",
     "evalue": "java.lang.NullPointerException: Cannot invoke \"moa.evaluation.BasicAUCImbalancedPerformanceEvaluator$Estimator.getAUC()\" because \"this.aucEstimator\" is null",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mBasicAUCImbalancedPerformanceEvaluator.java:393\u001b[0m, in \u001b[0;36mmoa.evaluation.BasicAUCImbalancedPerformanceEvaluator.getPerformanceMeasurements\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Java Exception",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mjava.lang.NullPointerException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     evaluator\u001b[38;5;241m.\u001b[39mupdate(instance\u001b[38;5;241m.\u001b[39my_index, proba)\n\u001b[0;32m     15\u001b[0m     learner\u001b[38;5;241m.\u001b[39mtrain(instance)\n\u001b[1;32m---> 16\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\evaluation\\evaluation.py:507\u001b[0m, in \u001b[0;36mAnomalyDetectionEvaluator.auc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 507\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics()[index]\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Nacional de Colombia\\Documentos\\Institut Polytechnique de Paris\\courses\\P1\\Data Streaming\\project\\actual code\\CapyMOA\\src\\capymoa\\evaluation\\evaluation.py:484\u001b[0m, in \u001b[0;36mAnomalyDetectionEvaluator.metrics_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetrics_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 484\u001b[0m     performance_measurements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoa_basic_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetPerformanceMeasurements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m     performance_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    486\u001b[0m         _translate_metric_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(measurement\u001b[38;5;241m.\u001b[39mgetName()), to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapymoa\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m measurement \u001b[38;5;129;01min\u001b[39;00m performance_measurements\n\u001b[0;32m    488\u001b[0m     ]\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m performance_names\n",
      "\u001b[1;31mjava.lang.NullPointerException\u001b[0m: java.lang.NullPointerException: Cannot invoke \"moa.evaluation.BasicAUCImbalancedPerformanceEvaluator$Estimator.getAUC()\" because \"this.aucEstimator\" is null"
     ]
    }
   ],
   "source": [
    "stream = ElectricityTiny()\n",
    "stream.restart()\n",
    "schema = stream.get_schema()\n",
    "learner = Autoencoder(schema)\n",
    "evaluator = AnomalyDetectionEvaluator(schema)\n",
    "#while stream.has_more_instances():\n",
    "while processed_instances < 1000:    \n",
    "    instance = stream.next_instance()\n",
    "    proba = learner.score_instance(instance)\n",
    "    if proba > 1:\n",
    "        print('probability bigger than 1 for instance ', instance.x)\n",
    "        print(proba)\n",
    "    #score â€“ The predicted scores. Should be in the range [0, 1].\n",
    "    evaluator.update(instance.y_index, proba)\n",
    "    learner.train(instance)\n",
    "auc = evaluator.auc()\n",
    "print(f\"AUC: {auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our StreamRHF initialized\n",
      "probability bigger than 1 for instance  [0.170213 0.041161 0.13493  0.003467 0.422915 0.414912]\n",
      "1.5532632506624904\n",
      "probability bigger than 1 for instance  [0.191489 0.041161 0.140583 0.003467 0.422915 0.414912]\n",
      "1.979999999929308\n",
      "probability bigger than 1 for instance  [0.212766 0.044374 0.168997 0.003467 0.422915 0.414912]\n",
      "1.2929100772106497\n",
      "probability bigger than 1 for instance  [0.361702 0.040711 0.493306 0.003467 0.422915 0.414912]\n",
      "1.0452681454222659\n",
      "probability bigger than 1 for instance  [0.382979 0.041041 0.53258  0.003467 0.422915 0.414912]\n",
      "1.2386234337800872\n",
      "probability bigger than 1 for instance  [0.404255 0.041161 0.546415 0.003467 0.422915 0.414912]\n",
      "1.4093322616094195\n",
      "Processed 100 instances. Time spent: 17.63 seconds.\n",
      "AUC: 0.74 with StreamRHF\n"
     ]
    }
   ],
   "source": [
    "stream = ElectricityTiny()\n",
    "schema = stream.get_schema()\n",
    "learner = StreamRHF(schema)\n",
    "evaluator = AnomalyDetectionEvaluator(schema)\n",
    "start_time = time.time()\n",
    "processed_instances = 0\n",
    "#while stream.has_more_instances():\n",
    "while processed_instances < 100:\n",
    "    instance = stream.next_instance()\n",
    "    proba = learner.score_instance(instance)\n",
    "    if proba > 1:\n",
    "        print('probability bigger than 1 for instance ', instance.x)\n",
    "        print(proba)\n",
    "    #score â€“ The predicted scores. Should be in the range [0, 1].\n",
    "    evaluator.update(instance.y_index, proba)\n",
    "    learner.train(instance)\n",
    "    processed_instances += 1\n",
    "    # Print progress and elapsed time every 100 instances\n",
    "    if processed_instances % 100 == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Processed {processed_instances} instances. Time spent: {elapsed_time:.2f} seconds.\")\n",
    "        start_time = time.time()  # Reset start time for the next 100 instances\n",
    "auc = evaluator.auc()\n",
    "print(f\"AUC: {auc:.2f} with StreamRHF\")\n",
    "stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectricityTiny type:  <class 'capymoa.datasets._datasets.ElectricityTiny'>\n",
      "@relation electricity\n",
      "\n",
      "@attribute period numeric\n",
      "@attribute nswprice numeric\n",
      "@attribute nswdemand numeric\n",
      "@attribute vicprice numeric\n",
      "@attribute vicdemand numeric\n",
      "@attribute transfer numeric\n",
      "@attribute class {0,1}\n",
      "\n",
      "@data\n"
     ]
    }
   ],
   "source": [
    "print(\"ElectricityTiny type: \", type(stream))\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Configuration: AUC = 0.50\n",
      "More Trees: AUC = 0.50\n",
      "Deeper Trees: AUC = 0.50\n",
      "Smaller Window: AUC = 0.50\n",
      "\n",
      "Summary of AUC Scores:\n",
      "Default Configuration: 0.50\n",
      "More Trees: 0.50\n",
      "Deeper Trees: 0.50\n",
      "Smaller Window: 0.50\n",
      "\n",
      "Metrics for Default Configuration:\n",
      "[45312.0, 0.5, -0.5, 0.5754546257062146, 0.0, 1.3554608306908562, 0.0, 1.0, -0.0002079758747985337]\n",
      "\n",
      "Metrics for More Trees:\n",
      "[45312.0, 0.5, -0.5, 0.5754546257062146, 0.0, 1.3554608306908562, 0.0, 1.0, -0.0002079758747985337]\n",
      "\n",
      "Metrics for Deeper Trees:\n",
      "[45312.0, 0.5, -0.5, 0.5754546257062146, 0.0, 1.3554608306908562, 0.0, 1.0, -0.0002079758747985337]\n",
      "\n",
      "Metrics for Smaller Window:\n",
      "[45312.0, 0.5, -0.5, 0.5754546257062146, 0.0, 1.3554608306908562, 0.0, 1.0, -0.0002079758747985337]\n"
     ]
    }
   ],
   "source": [
    "# Define the function to evaluate a given learner on the stream\n",
    "def evaluate_anomaly_learner(stream, learner, label):\n",
    "    schema = stream.get_schema()\n",
    "    evaluator = AnomalyDetectionEvaluator(schema)\n",
    "    while stream.has_more_instances():\n",
    "        instance = stream.next_instance()\n",
    "        proba = learner.score_instance(instance)\n",
    "        evaluator.update(instance.y_index, proba)\n",
    "        learner.train(instance)\n",
    "    auc = evaluator.auc()\n",
    "    print(f\"{label}: AUC = {auc:.2f}\")\n",
    "    return {\n",
    "        \"learner\": label,\n",
    "        \"auc\": auc,\n",
    "        \"evaluator\": evaluator,\n",
    "    }\n",
    "\n",
    "# Stream setup\n",
    "stream = Electricity()\n",
    "\n",
    "# Define configurations of TreeBasedUnsupervised to evaluate\n",
    "learners = [\n",
    "    {\"label\": \"Default Configuration\", \"params\": {}},\n",
    "    {\"label\": \"More Trees\", \"params\": {\"num_trees\": 100}},\n",
    "    {\"label\": \"Deeper Trees\", \"params\": {\"max_height\": 1000}},\n",
    "    {\"label\": \"Smaller Window\", \"params\": {\"window_size\": 50}},\n",
    "]\n",
    "\n",
    "# Evaluate all configurations\n",
    "results = []\n",
    "for config in learners:\n",
    "    stream = Electricity()  # Reset the stream for each learner\n",
    "    learner = TreeBasedUnsupervised(schema=stream.get_schema(), **config[\"params\"])\n",
    "    result = evaluate_anomaly_learner(stream, learner, config[\"label\"])\n",
    "    results.append(result)\n",
    "\n",
    "# Print summary of all results\n",
    "print(\"\\nSummary of AUC Scores:\")\n",
    "for result in results:\n",
    "    print(f\"{result['learner']}: {result['auc']:.2f}\")\n",
    "\n",
    "# Optional: Access metrics for further analysis or visualization\n",
    "for result in results:\n",
    "    print(f\"\\nMetrics for {result['learner']}:\")\n",
    "    print(result[\"evaluator\"].metrics())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
